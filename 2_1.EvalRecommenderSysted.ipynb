{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5714285714285714\n",
      "Recall: 0.6071428571428572\n",
      "F1 Score: 0.5879120879120878\n",
      "Intra-list Diversity: {'user1': 2.75, 'user2': 2.75}\n",
      "Inter-list Diversity: 2.75\n",
      "Novelty Score: 0.42857142857142855\n",
      "Coverage Score: 1.0\n",
      "Click-through Rate: 0.75\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# Sample data\n",
    "# Dictionary containing user profiles where keys are user IDs and values are dictionaries representing user profiles.\n",
    "user_profile_data = {\n",
    "    'user1': {'Database': 1, 'Python': 1, 'CloudComputing': 0, 'DataAnalysis': 1, 'Containers': 0, 'MachineLearning': 1, 'ComputerVision': 0, 'DataScience': 1, 'BigData': 0, 'Chatbot': 0, 'R': 1, 'BackendDev': 0, 'FrontendDev': 0, 'Blockchain': 0},\n",
    "    'user2': {'Database': 1, 'Python': 0, 'CloudComputing': 1, 'DataAnalysis': 1, 'Containers': 0, 'MachineLearning': 1, 'ComputerVision': 0, 'DataScience': 0, 'BigData': 1, 'Chatbot': 0, 'R': 1, 'BackendDev': 0, 'FrontendDev': 0, 'Blockchain': 1}\n",
    "}\n",
    "# Dictionary containing course genres where keys are course IDs and values are dictionaries representing course genres.\n",
    "course_genre_data = {\n",
    "    'course1': {'Database': 1, 'Python': 0, 'CloudComputing': 1, 'DataAnalysis': 1, 'Containers': 0, 'MachineLearning': 1, 'ComputerVision': 0, 'DataScience': 0, 'BigData': 1, 'Chatbot': 1, 'R': 0, 'BackendDev': 0, 'FrontendDev': 0, 'Blockchain': 1},\n",
    "    'course2': {'Database': 0, 'Python': 1, 'CloudComputing': 0, 'DataAnalysis': 1, 'Containers': 1, 'MachineLearning': 0, 'ComputerVision': 1, 'DataScience': 0, 'BigData': 1, 'Chatbot': 0, 'R': 1, 'BackendDev': 0, 'FrontendDev': 0, 'Blockchain': 1}\n",
    "}\n",
    "# Dictionary containing test data with keys 'user', 'item', and 'rating', where each key corresponds to a list of user IDs, course IDs, and ratings respectively.\n",
    "test_data = {\n",
    "    'user': ['user1', 'user1', 'user2', 'user2'],\n",
    "    'item': ['course1', 'course2', 'course1', 'course2'],\n",
    "    'rating': [1, 0, 1, 1]\n",
    "}\n",
    "\n",
    "# 2. Precision, Recall, and F1 Score Calculation (precision_recall_f1 function)\n",
    "# Iterate through the test data.\n",
    "# For each user-item pair:\n",
    "# Extract relevant courses from the user profile data.\n",
    "# Extract recommended genres from the course genre data.\n",
    "# Calculate precision, recall, and F1 score based on the overlap between relevant courses and recommended genres.\n",
    "# Compute averages of precision, recall, and F1 scores across all user-item pairs.\n",
    "def precision_recall_f1(test_data, user_profile_data, course_genre_data):\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    f1_score_sum = 0\n",
    "    for user, item, rating in zip(test_data['user'], test_data['item'], test_data['rating']):\n",
    "        if user in user_profile_data:\n",
    "            relevant_courses = [key for key, val in user_profile_data[user].items() if val == 1]\n",
    "            recommended_genres = [key for key, val in course_genre_data[item].items() if val == 1]\n",
    "            true_positives = len(set(relevant_courses) & set(recommended_genres))\n",
    "            precision = true_positives / len(recommended_genres) if len(recommended_genres) > 0 else 0\n",
    "            recall = true_positives / len(relevant_courses) if len(relevant_courses) > 0 else 0\n",
    "            precision_sum += precision\n",
    "            recall_sum += recall\n",
    "            f1_score_sum += 2 * ((precision * recall) / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "    precision_avg = precision_sum / len(test_data['user'])\n",
    "    recall_avg = recall_sum / len(test_data['user'])\n",
    "    f1_score_avg = f1_score_sum / len(test_data['user'])\n",
    "    return precision_avg, recall_avg, f1_score_avg\n",
    "\n",
    "def diversity_metrics(test_data, course_genre_data):\n",
    "    unique_genres_per_user = defaultdict(set)\n",
    "    total_unique_genres = set()\n",
    "    for user, item, rating in zip(test_data['user'], test_data['item'], test_data['rating']):\n",
    "        recommended_genres = [key for key, val in course_genre_data[item].items() if val == 1]\n",
    "        unique_genres_per_user[user].update(recommended_genres)\n",
    "        total_unique_genres.update(recommended_genres)\n",
    "    intra_list_diversity = {user: len(genres) / len(test_data['item']) for user, genres in unique_genres_per_user.items()}\n",
    "    inter_list_diversity = len(total_unique_genres) / len(test_data['item'])\n",
    "    return intra_list_diversity, inter_list_diversity\n",
    "def novelty(test_data, user_profile_data, course_genre_data):\n",
    "    novelty_scores = []\n",
    "    for user, item, rating in zip(test_data['user'], test_data['item'], test_data['rating']):\n",
    "        if user in user_profile_data:\n",
    "            relevant_courses = [key for key, val in user_profile_data[user].items() if val == 1]\n",
    "            recommended_genres = [key for key, val in course_genre_data[item].items() if val == 1]\n",
    "            novel_courses = [course for course in recommended_genres if course not in relevant_courses]\n",
    "            novelty_score = len(novel_courses) / len(recommended_genres) if len(recommended_genres) > 0 else 0\n",
    "            novelty_scores.append(novelty_score)\n",
    "    return sum(novelty_scores) / len(test_data['user'])\n",
    "def coverage(test_data, course_genre_data):\n",
    "    unique_recommendations = set(test_data['item'])\n",
    "    total_unique_courses = set(course_genre_data.keys())\n",
    "    coverage_score = len(unique_recommendations) / len(total_unique_courses) if len(total_unique_courses) > 0 else 0\n",
    "    return coverage_score\n",
    "def click_through_rate(test_data):\n",
    "    num_clicks = sum(test_data['rating'])\n",
    "    ctr = num_clicks / len(test_data['user'])\n",
    "    return ctr\n",
    "# Compute evaluation metrics\n",
    "precision, recall, f1_score = precision_recall_f1(test_data, user_profile_data, course_genre_data)\n",
    "intra_list_diversity, inter_list_diversity = diversity_metrics(test_data, course_genre_data)\n",
    "novelty_score = novelty(test_data, user_profile_data, course_genre_data)\n",
    "coverage_score = coverage(test_data, course_genre_data)\n",
    "ctr = click_through_rate(test_data)\n",
    "# Print results\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"Intra-list Diversity:\", intra_list_diversity)\n",
    "print(\"Inter-list Diversity:\", inter_list_diversity)\n",
    "print(\"Novelty Score:\", novelty_score)\n",
    "print(\"Coverage Score:\", coverage_score)\n",
    "print(\"Click-through Rate:\", ctr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(shahed3128)",
   "language": "python",
   "name": "shahed3128"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
